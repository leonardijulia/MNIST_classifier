{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59c73b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import rasterio as rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "534a2829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Local Disk\n",
      " Volume Serial Number is 6810-F594\n",
      "\n",
      " Directory of c:\\Users\\Julia\\OneDrive\\Dokumenty\\WORK\\PhD\\Conferences\\SummerSchool\\day3\\terramind\n",
      "\n",
      "06.06.2025  10:58    <DIR>          .\n",
      "05.06.2025  16:15    <DIR>          ..\n",
      "05.06.2025  16:15    <DIR>          .github\n",
      "05.06.2025  16:15    <DIR>          assets\n",
      "05.06.2025  16:15    <DIR>          configs\n",
      "05.06.2025  16:58    <DIR>          examples\n",
      "06.06.2025  11:31    <DIR>          experiments\n",
      "05.06.2025  16:15            11�546 LICENSE\n",
      "05.06.2025  16:55    <DIR>          notebooks\n",
      "05.06.2025  16:15             6�487 README.md\n",
      "05.06.2025  16:50    <DIR>          venv\n",
      "               2 File(s)         18�033 bytes\n",
      "               9 Dir(s)  761�820�504�064 bytes free\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "025339b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes=10):\n",
    "        \"\"\"\n",
    "        Define the layers of the convolutional neural network.\n",
    "\n",
    "        Parameters:\n",
    "            in_channels: int\n",
    "                The number of channels in the input image. For MNIST, this is 1 (grayscale images).\n",
    "            num_classes: int\n",
    "                The number of classes we want to predict, in our case 10 (digits 0 to 9).\n",
    "        \"\"\"\n",
    "        \n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # First convolutional layer: 1 input channel, 8 output channels, 3x3 kernel, stride 1, padding 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Max pooling layer: 2x2 window, stride 2\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Second convolutional layer: 8 input channels, 16 output channels, 3x3 kernel, stride 1, padding 1\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Fully connected layer: 16*7*7 input features (after two 2x2 poolings), 10 output features (num_classes)\n",
    "        self.fc1 = nn.Linear(16 * 7 * 7, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Define the forward pass of the neural network.\n",
    "\n",
    "        Parameters:\n",
    "            x: torch.Tensor\n",
    "                The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor\n",
    "                The output tensor after passing through the network.\n",
    "        \"\"\"\n",
    "        x = F.relu(self.conv1(x))  # Apply first convolution and ReLU activation\n",
    "        x = self.pool(x)           # Apply max pooling\n",
    "        x = F.relu(self.conv2(x))  # Apply second convolution and ReLU activation\n",
    "        x = self.pool(x)           # Apply max pooling\n",
    "        x = x.reshape(x.shape[0], -1)  # Flatten the tensor\n",
    "        x = self.fc1(x)            # Apply fully connected layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75140bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = rio.open('./examples/S2L2A/Singapore_2025-01-09.tif').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b2567c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d74cc22f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m model_cpu = CNN(in_channels=\u001b[32m12\u001b[39m,\n\u001b[32m      2\u001b[39m             num_classes=\u001b[32m10\u001b[39m).to(\u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m model_gpu = CNN(in_channels=\u001b[32m12\u001b[39m,\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m             num_classes=\u001b[32m10\u001b[39m).to(\u001b[43mdevice\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "model_cpu = CNN(in_channels=12,\n",
    "            num_classes=10).to('cpu')\n",
    "\n",
    "model_gpu = CNN(in_channels=12,\n",
    "            num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f418dcaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
